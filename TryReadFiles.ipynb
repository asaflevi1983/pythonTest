{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leviasaf\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 13, 301, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "import csv\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "\n",
    "csvfile=open('C:/Users/leviasaf/Desktop/halcon/barakpp12/cropped/result.txt');\n",
    "reader = csv.DictReader(csvfile)\n",
    "\n",
    "image_array  = np.empty([])\n",
    "image_labels=np.empty((1))\n",
    "\n",
    "img = image.load_img('C:/Users/leviasaf/Desktop/halcon/barakpp12/cropped/sample1.jpg',grayscale=True)  # this is a PIL image\n",
    "image_array_size = image.img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "image_array_size= image_array_size.reshape((1,) + image_array_size.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "image_array=np.empty(image_array_size.shape)\n",
    "image_array_size.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13, 301, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 13, 301, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(reader)\n",
    "for row in reader:\n",
    "  #  print(row['x'], row['y'],row['filePath'])\n",
    "    img=image.load_img(row['filePath'],grayscale=True)\n",
    "    x_value=row['x']\n",
    "    image_array= np.append(image_array,[image.img_to_array(img)],axis=0)\n",
    "    image_labels=np.append(image_labels,x_value)\n",
    "    #x = np.append(x, )\n",
    "\n",
    "image_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leviasaf\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, padding=\"same\", input_shape=(None, 13,..., kernel_size=(5, 5))`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_5: expected ndim=4, found ndim=5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb62239db352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m network.add(Convolution2D(nb_filters, kernel_size=(nb_conv, nb_conv),\n\u001b[1;32m     11\u001b[0m                         \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         input_shape=(None,13,301,1) ) )\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leviasaf\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leviasaf\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\leviasaf\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_5: expected ndim=4, found ndim=5"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta\n",
    "\n",
    "nb_filters = 8\n",
    "nb_conv=5\n",
    "network = Sequential()\n",
    "network.add(Convolution2D(nb_filters, kernel_size=(nb_conv, nb_conv),\n",
    "                        border_mode='same',\n",
    "                        input_shape=(None,13,301,1) ) )\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "network.add(Convolution2D(nb_filters,  kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "network.add(Convolution2D(nb_filters, kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "network.add(Convolution2D(nb_filters,  kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "network.add(keras.layers.core.Dropout(0.25))\n",
    "\n",
    "network.add(Convolution2D(nb_filters*2,  kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "network.add(Convolution2D(nb_filters*2,  kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters*2,  kernel_size=(nb_conv, nb_conv)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "network.add(Convolution2D(nb_filters*2,  kernel_size=(nb_conv, nb_conv)))\n",
    "network.add(Activation('relu'))\n",
    "network.add(keras.layers.core.Dropout(0.5))\n",
    "\n",
    "network.add(Flatten())\n",
    "network.add(Dense(256))\n",
    "network.add(Activation('relu'))\n",
    "network.add(keras.layers.core.Dropout(0.5))\n",
    "\n",
    "network.add(Dense(128))\n",
    "network.add(Activation('relu'))\n",
    "network.add(keras.layers.core.Dropout(0.5))\n",
    "\n",
    "network.add(Dense(1))\n",
    "network.add(Activation('linear'))\n",
    "\n",
    "network.compile(loss='mean_squared_error', optimizer=Adadelta())\n",
    "network.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fit(image_array,image_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_filters = 8\n",
    "nb_conv = 3\n",
    "\n",
    "network = Sequential()\n",
    "network.add(Convolution2D(nb_filters, kernel_size=(nb_conv, nb_conv),\n",
    "                        padding='same',\n",
    "                        input_shape=(13,301,1) ) )\n",
    "\n",
    "\n",
    "#network.add(Dense(1))\n",
    "network.add(Activation('linear'))\n",
    "\n",
    "network.compile(loss='mean_squared_error', optimizer=Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image_array=image_array.reshape((474,13*301))\n",
    "image_array = image_array.astype('float32') / 255\n",
    "\n",
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(13*301,)))\n",
    "network.add(layers.Dense(1, activation='linear'))\n",
    "network.compile(loss='mean_squared_error', optimizer=Adadelta())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
